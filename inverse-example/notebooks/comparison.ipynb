{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using Gurobi\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using Random\n",
    "using PDMats\n",
    "using MLJ\n",
    "using Tables\n",
    "using DataFrames\n",
    "\n",
    "Random.seed!(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "includet(\"../models/forward.jl\")\n",
    "import .Forward as Forward\n",
    "\n",
    "includet(\"../models/inversedemand.jl\")\n",
    "import .InverseDemand as IODemand\n",
    "\n",
    "includet(\"../models/inverselinreg.jl\")\n",
    "import .InverseLinReg as IOLinReg\n",
    "\n",
    "includet(\"../datagen/data-generation.jl\")\n",
    "import .DataGeneration as DataGen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear = @load LinearRegressor pkg = \"MLJLinearModels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for tomorrow:\n",
    "1. Save two datasets\n",
    "4. Split each dataset into train and test sets\n",
    "5. Run DFL-IO with each training set, get weights $\\theta^{\\text{IO,close}}$ and $\\theta^{\\text{IO,wide}}$\n",
    "6. Run linear regression on training set, get weights $\\theta^{\\text{R,close}}$ and $\\theta^{\\text{R,wide}}$\n",
    "7. Compare all models on each training set, for each model:\n",
    "    1. Predict demand using weights and features\n",
    "    2. Solve MCFND with demand, get design variables $\\hat{y}$\n",
    "    3. Solve MCF-Flow with fixed design variables $\\hat{y}$, get $\\hat{x}$\n",
    "    4. Compare costs of $\\hat{y}, \\hat{x}$ with optimal $x^*, y^*$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem parameters\n",
    "\n",
    "Make a smaller problem with 1 commodity and 2 possible arcs, one low-ish capacity ($C$) and one high ($\\infty$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_params = Forward.Params(\n",
    "    n_paths=2, \n",
    "    n_commodities=1,\n",
    "    capacities=[100, 100000],\n",
    "    design_costs=[10, 100],\n",
    "    flow_costs=[10 100]',\n",
    "    enabled_flows=ones(Bool, (2, 1))\n",
    ")\n",
    "\n",
    "datagen_params = DataGen.DataGenParams(\n",
    "    weights=[1.5 -3 2], \n",
    "    noise_variance=[5.0^2]\n",
    ")\n",
    "\n",
    "inverse_params = IOLinReg.Params(\n",
    "    n_features=datagen_params.n_features, \n",
    "    forward_params=forward_params, \n",
    "    with_noise=true\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "\n",
    "Generate two datasets using fixed weights $\\Theta$:\n",
    "- $\\mathcal{D}_{\\text{close}}$ with $\\mathbb{E}[d] = C$ \n",
    "- $\\mathcal{D}_{\\text{wide}}$ with $\\mathbb{E}[d] \\ll C$. \n",
    "\n",
    "Procedure for each data point in the dataset:\n",
    "1. Draw $\\phi_1, \\ldots, \\phi_{m-1} \\sim U(a, b)$ for some $a, b$\n",
    "2. Set $\\phi_m$ such that $\\sum_{i=1}^m \\theta_i \\phi_i = \\mathbb{E}[d]$\n",
    "3. Draw noise $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ and compute $d = \\sum_{i=1}^m \\theta_i \\phi_i + \\epsilon$\n",
    "4. Solve MCFND for $d$ \n",
    "5. Datapoint $(\\phi, d, x^*, y^*) \\in \\mathcal{D}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "gurobi_env = Gurobi.Env()\n",
    "\n",
    "close_target_demand = 100\n",
    "wide_target_demand = 20\n",
    "\n",
    "close_dataset = DataGen.generate_dataset(forward_params, datagen_params, n_points=n_points, target_demand=close_target_demand, gurobi_env=gurobi_env)\n",
    "wide_dataset = DataGen.generate_dataset(forward_params, datagen_params, n_points=n_points, target_demand=wide_target_demand, gurobi_env=gurobi_env)\n",
    "\n",
    "show(close_dataset[1])\n",
    "println()\n",
    "show(wide_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split each dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_split = 0.8\n",
    "\n",
    "close_train_dataset, close_test_dataset = partition(close_dataset, test_train_split)\n",
    "wide_train_dataset, wide_test_dataset = partition(wide_dataset, test_train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse-DFL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_inverse_model(training_dataset)\n",
    "    model = IOLinReg.create_problem(inverse_params, training_dataset, gurobi_env=gurobi_env)\n",
    "\n",
    "    return IOLinReg.solve_problem!(model, inverse_params)\n",
    "end\n",
    "\n",
    "close_inverse_solution = train_inverse_model(close_train_dataset)\n",
    "wide_inverse_solution = train_inverse_model(wide_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"IO model close weights: $(close_inverse_solution.weights)\")\n",
    "println(\"IO model wide weights: $(wide_inverse_solution.weights)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function convert_dataset_to_mlj(dataset)\n",
    "    features = DataFrame(vcat(map(sol -> sol.linreg_features', dataset)...), :auto)\n",
    "    demands = vcat(map(sol -> sol.actual_demands, dataset)...)\n",
    "\n",
    "    return features, demands\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_linear_model(training_dataset)\n",
    "    features, demands = convert_dataset_to_mlj(training_dataset)\n",
    "\n",
    "    model = Linear()\n",
    "    mach = machine(model, features, demands)\n",
    "    fit!(mach)\n",
    "\n",
    "    return mach\n",
    "end\n",
    "\n",
    "close_linreg_machine = train_linear_model(close_train_dataset)\n",
    "wide_linreg_machine = train_linear_model(wide_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the inverse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_inverse_model(inverse_solution, test_dataset)\n",
    "    features = map(row -> row.linreg_features, test_dataset)\n",
    "    predict = f -> IOLinReg.predict_inverse_model(inverse_solution, f)\n",
    "\n",
    "    return vcat(map(predict, features)...)\n",
    "end\n",
    "\n",
    "close_io_pred_demands = predict_inverse_model(close_inverse_solution, close_test_dataset)\n",
    "wide_io_pred_demands = predict_inverse_model(wide_inverse_solution, wide_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_linear_model(linreg_machine, test_dataset)\n",
    "    features, _ = convert_dataset_to_mlj(test_dataset)\n",
    "    return predict(linreg_machine, features)\n",
    "end\n",
    "\n",
    "close_linreg_pred_demands = predict_linear_model(close_linreg_machine, close_test_dataset)\n",
    "wide_linreg_pred_demands = predict_linear_model(wide_linreg_machine, wide_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
