{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing linear regression and DFL-IO\n",
    "\n",
    "Steps comparing the linear and inverse-DFL models:\n",
    "1. Save two datasets\n",
    "4. Split each dataset into train and test sets\n",
    "5. Run DFL-IO with each training set, get weights $\\theta^{\\text{IO,close}}$ and $\\theta^{\\text{IO,wide}}$\n",
    "6. Run linear regression on training set, get weights $\\theta^{\\text{R,close}}$ and $\\theta^{\\text{R,wide}}$\n",
    "7. Compare all models on each training set, for each model:\n",
    "    1. Predict demand using weights and features\n",
    "    2. Solve MCFND with demand, get design variables $\\hat{y}$\n",
    "    3. Solve MCF-Flow with fixed design variables $\\hat{y}$, get $\\hat{x}$\n",
    "    4. Compare costs of $\\hat{y}, \\hat{x}$ with optimal $x^*, y^*$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Gurobi\n",
    "using LinearAlgebra\n",
    "using Distributions, Random, PDMats\n",
    "using MLJ, Tables\n",
    "using DataFrames, DataFramesMeta\n",
    "using JLD, CSV\n",
    "using PlotlyJS\n",
    "using Pipe\n",
    "using LaTeXStrings\n",
    "\n",
    "Random.seed!(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "includet(\"../models/forward.jl\")\n",
    "import .Forward as Forward\n",
    "\n",
    "includet(\"../models/inversedemand.jl\")\n",
    "import .InverseDemand as IODemand\n",
    "\n",
    "includet(\"../models/inverselinreg.jl\")\n",
    "import .InverseLinReg as IOLinReg\n",
    "\n",
    "includet(\"../datagen/data-generation.jl\")\n",
    "import .DataGeneration as DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear = @MLJ.load LinearRegressor pkg = \"MLJLinearModels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = \"../data/\"\n",
    "BASE_RESULTS_PATH = \"../results/\"\n",
    "\n",
    "CLOSE_DATA_NAME = \"close\"\n",
    "WIDE_DATA_NAME = \"wide\"\n",
    "\n",
    "function dataset_path(n_points)\n",
    "    return joinpath(BASE_DATA_PATH, \"data_$n_points.jld\") \n",
    "end\n",
    "\n",
    "function results_path(n_points)\n",
    "    return joinpath(BASE_RESULTS_PATH, \"results_$n_points.csv\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a smaller problem with 1 commodity and 2 possible arcs, one low-ish capacity ($C$) and one high ($\\infty$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_params = Forward.Params(\n",
    "    n_paths=2, \n",
    "    n_commodities=1,\n",
    "    capacities=[100, 100000],\n",
    "    design_costs=[10, 100],\n",
    "    flow_costs=[10 100]',\n",
    "    enabled_flows=ones(Bool, (2, 1))\n",
    ")\n",
    "\n",
    "datagen_params = DataGen.DataGenParams(\n",
    "    weights=[1.5 -3 2], \n",
    "    noise_variance=[5.0^2]\n",
    ")\n",
    "\n",
    "inverse_params = IOLinReg.Params(\n",
    "    n_features=datagen_params.n_features, \n",
    "    forward_params=forward_params, \n",
    "    with_noise=true\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "Generate two datasets using fixed weights $\\Theta$:\n",
    "- $\\mathcal{D}_{\\text{close}}$ with $\\mathbb{E}[d] = C$ \n",
    "- $\\mathcal{D}_{\\text{wide}}$ with $\\mathbb{E}[d] \\ll C$. \n",
    "\n",
    "Procedure for each data point in the dataset:\n",
    "1. Draw $\\phi_1, \\ldots, \\phi_{m-1} \\sim U(a, b)$ for some $a, b$\n",
    "2. Set $\\phi_m$ such that $\\sum_{i=1}^m \\theta_i \\phi_i = \\mathbb{E}[d]$\n",
    "3. Draw noise $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ and compute $d = \\sum_{i=1}^m \\theta_i \\phi_i + \\epsilon$\n",
    "4. Solve MCFND for $d$ \n",
    "5. Datapoint $(\\phi, d, x^*, y^*) \\in \\mathcal{D}$\n",
    "\n",
    "Repeat dataset creation for several number of points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = [100, 1000, 3000, 10000]\n",
    "close_target_demand = 100\n",
    "wide_target_demand = 20\n",
    "\n",
    "gurobi_env = Gurobi.Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in n_points\n",
    "    close_dataset = DataGen.generate_dataset(forward_params, datagen_params, n_points=n, target_demand=close_target_demand, gurobi_env=gurobi_env)\n",
    "    wide_dataset = DataGen.generate_dataset(forward_params, datagen_params, n_points=n, target_demand=wide_target_demand, gurobi_env=gurobi_env)\n",
    "\n",
    "    save(dataset_path(n), CLOSE_DATA_NAME, close_dataset, WIDE_DATA_NAME, wide_dataset, compress=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a training function and a prediction function for each model:\n",
    "- `train_{model_type}_model` takes in a training dataset of `IOLinReg.SolutionPoint`s, and returns a trained model\n",
    "- `predict_{model_type}_model` takes a model of the correct type and a test dataset of `IOLinReg.SolutionPoint`s, and returns a vector of predicted demands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_dataset(n_points)\n",
    "    dataset = JLD.load(dataset_path(n_points))\n",
    "\n",
    "    return dataset[CLOSE_DATA_NAME], dataset[WIDE_DATA_NAME]\n",
    "end\n",
    "\n",
    "function convert_dataset_to_mlj(dataset)\n",
    "    features = DataFrame(vcat(map(sol -> sol.linreg_features', dataset)...), :auto)\n",
    "    demands = vcat(map(sol -> sol.actual_demands, dataset)...)\n",
    "\n",
    "    return features, demands\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFL-IO model training and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_inverse_model(training_dataset)\n",
    "    model = IOLinReg.create_problem(inverse_params, training_dataset, gurobi_env=gurobi_env)\n",
    "\n",
    "    return IOLinReg.solve_problem!(model, inverse_params)\n",
    "end\n",
    "\n",
    "function predict_inverse_model(inverse_solution, test_dataset)\n",
    "    features = map(row -> row.linreg_features, test_dataset)\n",
    "    predict = f -> IOLinReg.predict_inverse_model(inverse_solution, f)\n",
    "\n",
    "    return vcat(map(predict, features)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression model training and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_linear_model(training_dataset)\n",
    "    features, demands = convert_dataset_to_mlj(training_dataset)\n",
    "\n",
    "    model = Linear()\n",
    "    mach = machine(model, features, demands)\n",
    "    fit!(mach)\n",
    "\n",
    "    return mach\n",
    "end\n",
    "\n",
    "function predict_linear_model(linreg_machine, test_dataset)\n",
    "    features, _ = convert_dataset_to_mlj(test_dataset)\n",
    "    return predict(linreg_machine, features)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an evaluation procedure `evaluate_model_on_dataset` as described in point 5 of the introduction. Takes a train and test dataset, and a training and prediction function for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_model_on_dataset(train_data, test_data, train_model, make_predictions; gurobi_env=nothing)  \n",
    "    trained_model = train_model(train_data)\n",
    "    predicted_demands = make_predictions(trained_model, test_data)\n",
    "    designed_network = compute_predicted_network_design(forward_params, predicted_demands, gurobi_env=gurobi_env)\n",
    "\n",
    "    return compute_flow_problem_results(forward_params, test_data, designed_network, predicted_demands)\n",
    "end\n",
    "\n",
    "function compute_predicted_network_design(forward_params, predicted_demands; gurobi_env=nothing)\n",
    "    solve_mcfnd = d -> Forward.create_and_solve_problem(forward_params, d, silent=true, gurobi_env=gurobi_env)\n",
    "    return map(d -> solve_mcfnd(d).z_sol, predicted_demands) \n",
    "end\n",
    "\n",
    "function compute_flow_problem_results(forward_params, test_dataset, predicted_z_sols, predicted_demands; gurobi_env=gurobi_env)\n",
    "    actual_demands = map(row -> row.actual_demands, test_dataset)\n",
    "    solve_flow = (d, z_sol) -> Forward.create_and_solve_flow_problem(forward_params, d, z_sol, silent=true, gurobi_env=gurobi_env)\n",
    "    forward_solutions = map(solve_flow, actual_demands, predicted_z_sols)\n",
    "    \n",
    "    task_losses = map(sol -> sol.objective_value, forward_solutions)\n",
    "    recourse_flow = map(sol -> sol.recourse_flow, forward_solutions)\n",
    "    \n",
    "    return DataFrame(\n",
    "        task_loss=task_losses, \n",
    "        recourse_flow=recourse_flow, \n",
    "        predicted_demand=predicted_demands, \n",
    "        actual_demand=map(first, actual_demands)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison pipeline and result cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given full dataset of `n_points`, obtain the results of the DFL-IO and the Linear Regression model over the close and wide datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compare_models(n_points; test_train_split=0.7)\n",
    "    close_dataset, wide_dataset = load_dataset(n_points)\n",
    "\n",
    "    close_train, close_test = partition(close_dataset, test_train_split)\n",
    "    wide_train, wide_test =  partition(wide_dataset, test_train_split)\n",
    "\n",
    "    close_io_results = evaluate_model_on_dataset(close_train, close_test, train_inverse_model, predict_inverse_model, gurobi_env=gurobi_env)\n",
    "    close_linreg_results = evaluate_model_on_dataset(close_train, close_test, train_linear_model, predict_linear_model, gurobi_env=gurobi_env)\n",
    "    wide_io_results = evaluate_model_on_dataset(wide_train, wide_test, train_inverse_model, predict_inverse_model, gurobi_env=gurobi_env)\n",
    "    wide_linreg_results = evaluate_model_on_dataset(wide_train, wide_test, train_linear_model, predict_linear_model, gurobi_env=gurobi_env)\n",
    "\n",
    "    return vcat(\n",
    "        specify_model_and_data(close_io_results, \"close\", \"io\"),\n",
    "        specify_model_and_data(close_linreg_results, \"close\", \"linreg\"),\n",
    "        specify_model_and_data(wide_io_results, \"wide\", \"io\"),\n",
    "        specify_model_and_data(wide_linreg_results, \"wide\", \"linreg\")\n",
    "    )\n",
    "end\n",
    "\n",
    "\n",
    "function specify_model_and_data(results_data, data_type, model_type)\n",
    "    length = nrow(results_data)\n",
    "\n",
    "    data_column = categorical(fill(data_type, length))\n",
    "    model_column = categorical(fill(model_type, length))\n",
    "\n",
    "    types_df = DataFrame(dataset=data_column, model=model_column)\n",
    "\n",
    "    return hcat(results_data, types_df)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and storing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = [n => compare_models(n) for n in n_points]\n",
    "\n",
    "for (n, res) in all_results\n",
    "    CSV.write(results_path(n), res)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = vcat([\n",
    "    hcat(res, DataFrame(:n_points => fill(n, nrows(res))))\n",
    "    for (n, res) in all_results\n",
    "]...)\n",
    "\n",
    "CSV.write(results_path(\"all\"), combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_results(n_points)\n",
    "    results = CSV.read(results_path(n_points), DataFrame)\n",
    "\n",
    "    if \"n_points\" âˆ‰ names(results)\n",
    "        @transform!(results, :n_points = fill(\"$n_points\", nrow(results)))\n",
    "    end\n",
    "\n",
    "    @transform!(results, :dataset = categorical(:dataset))\n",
    "    @transform!(results, :model = categorical(:model))\n",
    "    @transform!(results, :n_points = string.(:n_points))\n",
    "\n",
    "    return results\n",
    "end\n",
    "\n",
    "results = load_results(\"all\")\n",
    "subresults = [n => load_results(n) for n in n_points]\n",
    "\n",
    "first(results, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recouse paths and model robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No point in the wide dataset ever uses recourse flow, so we filter that dataset out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results.dataset .== \"wide\" .&& results.recourse_flow .> 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function analyze_n_recourse(res)\n",
    "    return @chain res begin \n",
    "        groupby([:n_points, :dataset, :model])\n",
    "        subset(:dataset => d -> d .!= \"wide\", ungroup=false)\n",
    "        combine(:recourse_flow => (r -> count(x -> x .> 0, r)) => :n_recourse,\n",
    "                :recourse_flow => (r -> count(x -> x .> 0, r) / nrows(r)) => :frac_recourse,\n",
    "                :recourse_flow => mean)\n",
    "        sort(:n_points, by=n -> parse(Int, n))\n",
    "        @transform(:pct_recourse = 100 .* :frac_recourse)\n",
    "        @transform(:str_pct_recourse = string.(round.(:pct_recourse, digits=1), \"%\"))\n",
    "    end\n",
    "end\n",
    "\n",
    "recourse_analysis = analyze_n_recourse(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First analyse, for every model and dataset, how many predicted demands result in having to use the recourse path. We are testing the robustness of the prediction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    recourse_analysis,\n",
    "    kind=\"bar\",\n",
    "    y=:pct_recourse,\n",
    "    text=:str_pct_recourse,\n",
    "    facet_col=:n_points, \n",
    "    color=:model,\n",
    "    Layout(\n",
    "        xaxis_title=\"\",\n",
    "        yaxis_title=\"% using recourse path\",\n",
    "        title=\"Percentage of predicted demands that need to use recourse path, compared between DFL-IO and Linear Regression\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then look at the distribution of the flow over the recourse path for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recourses = @chain results begin\n",
    "    subset(:recourse_flow => f -> f .> 0)\n",
    "    subset(:dataset => d -> d .!= \"wide\")\n",
    "end\n",
    "\n",
    "first(all_recourses, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    all_recourses,\n",
    "    kind=\"histogram\",\n",
    "    x=:recourse_flow,\n",
    "    facet_col=:n_points, \n",
    "    color=:model,\n",
    "    opacity=0.5,\n",
    "    Layout(\n",
    "        xaxis_title=\"Amount of recourse flow\",\n",
    "        yaxis_title=\"# of occurences\",\n",
    "        title=\"Distribution of recourse flow amount for DFL-IO and Linear Regression models\",\n",
    "        barmode=\"overlay\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain results begin\n",
    "    subset(:recourse_flow => r -> r .<= 0)\n",
    "    groupby([:n_points, :dataset, :model])\n",
    "    combine(:task_loss => (x -> [(mean(x), median(x), extrema(x)...)]) => [:mean, :median, :min, :max])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    subset(results, :recourse_flow => r -> r .<= 0),\n",
    "    kind=\"box\",\n",
    "    x=:task_loss,\n",
    "    facet_row=:n_points,\n",
    "    facet_col=:dataset,\n",
    "    color=:model,\n",
    "    Layout(\n",
    "        height=1000,\n",
    "        title=\"Comparison of task losses between IO and Linear Regression, by dataset type and #points\",\n",
    "        #xaxis_title=\"task_loss\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_task_loss_distributions(results, dataset)\n",
    "    no_recourse_results = @chain results begin\n",
    "        subset(:recourse_flow => r -> r .<= 0)\n",
    "        subset(:dataset => d -> d .== dataset)\n",
    "    end\n",
    "    \n",
    "    return plot(\n",
    "        no_recourse_results,\n",
    "        kind=\"histogram\",\n",
    "        x=:task_loss,\n",
    "        facet_row=:n_points, \n",
    "        color=:model,\n",
    "        opacity=0.5,\n",
    "        Layout(\n",
    "            xaxis_title=\"\",\n",
    "            yaxis_title=\"\",\n",
    "            title=\"\",\n",
    "            barmode=\"overlay\",\n",
    "            height=\"1000\",\n",
    "            width=\"700\"\n",
    "        )\n",
    "    )\n",
    "end\n",
    "\n",
    "plot_task_loss_distributions(results, \"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_task_loss_distributions(results, \"wide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of predicted demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_io = @chain results begin\n",
    "    subset(:model => m -> m .== \"io\")\n",
    "    @rename(:pred_io = :predicted_demand, :recourse_io = :recourse_flow)\n",
    "    select(:dataset, :n_points, :pred_io, :recourse_io)\n",
    "end \n",
    "\n",
    "pred_linreg = @chain results begin\n",
    "    subset(:model => m -> m .== \"linreg\")\n",
    "    @rename(:pred_linreg = :predicted_demand, :recourse_linreg = :recourse_flow)\n",
    "    select(:pred_linreg, :recourse_linreg)\n",
    "end\n",
    "\n",
    "pred_compared = hcat(pred_io, pred_linreg)\n",
    "\n",
    "first(pred_compared, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorise_compared_recourse(recourse_flow_io, recourse_flow_linreg)\n",
    "    if recourse_flow_io .> 0 && recourse_flow_linreg .> 0\n",
    "        return \"both\"\n",
    "    elseif recourse_flow_io .> 0\n",
    "        return \"io\"\n",
    "    elseif recourse_flow_linreg > 0\n",
    "        return \"linreg\"\n",
    "    end\n",
    "    \n",
    "    return \"none\"\n",
    "end\n",
    "\n",
    "function plot_prediction_comparison(pred_compared, n_points, dataset)\n",
    "    filtered = @chain pred_compared begin\n",
    "        @subset(:n_points .== \"$n_points\")\n",
    "        @subset(:dataset .== dataset)\n",
    "        @transform(@byrow :recourse_use = categorise_compared_recourse(:recourse_io, :recourse_linreg))\n",
    "    end\n",
    "\n",
    "    mn, mx = extrema(vcat(filtered.pred_io, filtered.pred_linreg))\n",
    "    t = mn:0.01:mx\n",
    "\n",
    "    return plot(\n",
    "        [\n",
    "            scatter(x=t, y=t, mode=\"lines\", name=\"Identity\"),\n",
    "            scatter(filtered[filtered.recourse_use .== \"none\", :], x=:pred_linreg, y=:pred_io, mode=\"markers\", name=\"No model uses recourse\"),\n",
    "            scatter(filtered[filtered.recourse_use .== \"io\", :], x=:pred_linreg, y=:pred_io, mode=\"markers\", name=\"Only DFL-IO uses recourse\"),\n",
    "            scatter(filtered[filtered.recourse_use .== \"linreg\", :], x=:pred_linreg, y=:pred_io, mode=\"markers\", name=\"Only LinReg uses recourse\"),\n",
    "            scatter(filtered[filtered.recourse_use .== \"both\", :], x=:pred_linreg, y=:pred_io, mode=\"markers\", name=\"Both models use recourse\")\n",
    "        ],\n",
    "        Layout(\n",
    "            xaxis_title=\"Predicted demand (Linear Regression)\",\n",
    "            yaxis_title=\"Predicted demand (DFL-IO)\"\n",
    "        )\n",
    "    )\n",
    "end\n",
    "\n",
    "plot_prediction_comparison(pred_compared, 100, \"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_comparison(pred_compared, 1000, \"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_comparison(pred_compared, 3000, \"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_comparison(pred_compared, 10000, \"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_comparison(pred_compared, 100, \"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_comparison(pred_compared, 1000, \"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_comparison(pred_compared, 3000, \"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_comparison(pred_compared, 10000, \"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
